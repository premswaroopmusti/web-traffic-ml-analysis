# ğŸŒ Web Traffic Analysis & Classification  

This repository contains two projects focused on analyzing and classifying web traffic logs:  

1. **User-Agent Traffic Classification** â€“ Classify requests as **Good** or **Bad** traffic using ML models.  
2. **Web Traffic Log Analysis** â€“ Extract inferences from raw server logs (requests, IPs, referrers, status codes, user-agents, geolocation, etc.).  

---

## ğŸ¯ Objectives  

- Detect malicious/bad bots using **User-Agent string classification**.  
- Perform **deep exploratory analysis** of web traffic logs.  
- Derive insights like **requests per minute/hour, IP patterns, referrer sources, user-agent distribution, success/error rates, and geolocation trends**.  

---

## ğŸ“‚ Projects  

### ğŸ”¹ 1. User-Agent Traffic Classification  
- **Input:** Web traffic logs with `http_user_agent` field.  
- **Approach:**  
  - Label data using known bad/good bot keywords.  
  - Train & compare multiple ML algorithms (e.g., Logistic Regression, Naive Bayes).  
  - Classify requests as **Good** or **Bad**.  
- **Outcome:** Detect bad bot traffic with ML-driven classification.  

---

### ğŸ”¹ 2. Web Traffic Log Analysis  
- **Input:** Log data with `timestamp`, `request`, `remote_addr`, `http_referrer`, `status`, `http_user_agent`.  
- **Key Inferences:**  
  - ğŸ“Š **Requests per Minute/Hour** â†’ Average ~17 requests/minute, ~1078/hour.  
  - ğŸ•µï¸ **IP Analysis** â†’ Different IPs perform GET, POST, HEAD with varying distributions.  
  - ğŸŒ **Geolocation** â†’ IPs mapped to Mumbai, India (The Constant Company, LLC).  
  - ğŸ”— **Referrer Analysis** â†’ Majority traffic from `None`, followed by `prophaze.com`.  
  - ğŸ–¥ï¸ **User-Agent Analysis** â†’ Top devices: Windows NT 10.0, Linux, iPhone.  
  - ğŸŒ **Browser Analysis** â†’ Top: AppleWebKit, Gecko, Googlebot, AhrefsBot, etc.  
  - âœ… **Status Codes** â†’ ~94k successful vs ~35k unsuccessful requests.  
  - â° **Temporal Patterns** â†’ Peak traffic on `2023-08-11 04` (~22k requests), lowest during night hours.  

---

## ğŸ› ï¸ Tech Stack  

- **Languages:** Python (Pandas, NumPy, Regex, Collections)  
- **Visualization:** Matplotlib, Seaborn  
- **ML Models:** Logistic Regression, Naive Bayes (extendable to others)  
- **Tools:** Google Colab, ipinfo.io API (for geolocation)  

---

## ğŸš€ Usage  

1. Clone this repo:  
```
   git clone https://github.com/yourusername/web-traffic-analysis.git
   cd web-traffic-analysis
```
2. Install dependencies:
```
pip install -r requirements.txt
```

3. Open the notebooks in **Google Colab** or run locally:

- `user_agent_classification.ipynb` â†’ ML classification.

- `web_log_analysis.ipynb` â†’ Exploratory data analysis & inferences.

## Example Outputs

- **Requests per Minute**: 17 avg/min

- **Top Referrer**: `None (Direct)`

- **Top Device**: Windows NT 10.0

- **Top Browser**: AppleWebKit

- **Peak Traffic**: Aug 11, 04:00 (~22k requests)

## Future Work

- Add **deep learning models** (e.g., LSTM for sequence analysis).

- Automate referrer categorization (organic, direct, paid).

- Build a **real-time dashboard** using Streamlit/Plotly.

- Extend geolocation mapping with **heatmaps.**

## Contributing

Contributions are welcome! Feel free to fork, improve, and raise PRs.
